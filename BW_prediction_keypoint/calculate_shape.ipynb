{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1740520086667,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "V1CennVo0EdJ",
    "outputId": "c1ac9ef4-ead8-4967-9fbb-5369f9bc2dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!git clone https://github.com/Maria-Elisa-M/BW_prediction_keypoint.git\n",
    "os.chdir('BW_prediction_keypoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9038,
     "status": "ok",
     "timestamp": 1740520095711,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "RB7NOXD1FDp8",
    "outputId": "56c5760e-29d5-45ce-ddf1-1e159693aebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (2024.12.30)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install imagecodecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 966,
     "status": "ok",
     "timestamp": 1740520096676,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "RX9lOcTFx5yW"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.io import imsave\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "from scipy import ndimage as nd\n",
    "import math\n",
    "import imagecodecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgiXxnFvyh__"
   },
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740520096681,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "K-_U1Hkix9MM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_cow_day(filename):\n",
    "    \"\"\"Extracts cow ID and day from the filename, assuming format 'cowID_dayXXXXXX.png'\"\"\"\n",
    "    parts = filename.split(\"_\")\n",
    "    if len(parts) >= 2:\n",
    "        cow, day = parts[0], parts[1][:8]  # Extract cow ID and first 8 chars of day\n",
    "    else:\n",
    "        cow, day = np.nan, np.nan  # Assign NaN if format is incorrect\n",
    "    return cow, day\n",
    "\n",
    "def calculate_vertical_center_points(mask, num_points=13):\n",
    "    \"\"\"Calculate vertical center points along evenly spaced columns in the mask.\"\"\"\n",
    "    labeled_mask = label(mask)\n",
    "    properties = regionprops(labeled_mask)\n",
    "\n",
    "    if not properties:\n",
    "        return []\n",
    "\n",
    "    minr, minc, maxr, maxc = properties[0].bbox\n",
    "    spaced_columns = np.linspace(minc, maxc - 1, num=num_points, dtype=int)\n",
    "\n",
    "    center_points = []\n",
    "    for c in spaced_columns:\n",
    "        col = mask[minr:maxr, c]\n",
    "        if np.any(col):\n",
    "            top_edge = minr + np.argmax(col)\n",
    "            bottom_edge = maxr - np.argmax(col[::-1])\n",
    "            center_y = (top_edge + bottom_edge) // 2\n",
    "            width = bottom_edge - top_edge\n",
    "            center_points.append((center_y, c, top_edge, bottom_edge, width))\n",
    "\n",
    "    return center_points\n",
    "\n",
    "def calculate_shape_features(mask, depth, floor_distance=2225):\n",
    "    \"\"\"Compute shape features based on the mask and depth map.\"\"\"\n",
    "    if mask.size == 0:\n",
    "        return [0] * 7\n",
    "\n",
    "    pred_mask = mask.astype(bool)\n",
    "\n",
    "    # Handle invalid depth values\n",
    "    invalid_cell_mask = depth == 0\n",
    "    indices = nd.distance_transform_edt(invalid_cell_mask, return_distances=False, return_indices=True)\n",
    "    depth = depth[tuple(indices)]\n",
    "    depth[~pred_mask] = 0\n",
    "    depth[depth >= floor_distance] = 0\n",
    "    depth_to_floor = floor_distance - depth\n",
    "    depth_to_floor[depth == 0] = 0\n",
    "\n",
    "    # Camera parameters\n",
    "    focal_length = 0.6\n",
    "    sensor_size = 0.0014\n",
    "    f = focal_length / sensor_size\n",
    "    each_pixel_area = (depth / f) ** 2\n",
    "\n",
    "    # Compute features\n",
    "    area = np.sum(each_pixel_area) * 0.01  # cmÂ²\n",
    "    volume = np.sum(each_pixel_area * depth_to_floor) * 1e-6  # L\n",
    "\n",
    "    labeled_mask = label(pred_mask)\n",
    "    properties = regionprops(labeled_mask)\n",
    "\n",
    "    if not properties:\n",
    "        return [area, volume, 0, 0, 0, 0, 0]\n",
    "\n",
    "    prop = properties[0]\n",
    "    circularity = (4 * prop.area * math.pi) / (prop.perimeter ** 2) if prop.perimeter > 0 else 0\n",
    "    extent = prop.extent\n",
    "    eccentricity = prop.eccentricity\n",
    "    perimeter = prop.perimeter\n",
    "\n",
    "    # Compute major axis length using image rotation\n",
    "    imgrot = rotate(pred_mask, -prop.orientation * 180 / math.pi, resize=True)\n",
    "    hor = np.max(np.sum(imgrot, axis=1))\n",
    "    vert = np.max(np.sum(imgrot, axis=0))\n",
    "    major_axis_length = max(hor, vert)\n",
    "\n",
    "    return [area, volume, circularity, extent, eccentricity, perimeter, major_axis_length]\n",
    "\n",
    "def calculate_distances(depth_map, points):\n",
    "    \"\"\"Extract depth values at specified key points.\"\"\"\n",
    "    return [depth_map[int(y), int(x)] if (0 <= int(y) < depth_map.shape[0] and 0 <= int(x) < depth_map.shape[1]) else np.nan for y, x in points]\n",
    "\n",
    "def process_images(image_directory, mask_directory, output_directory):\n",
    "    \"\"\"Process depth and mask images, extract features, and save results.\"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    mask_files = [f for f in os.listdir(mask_directory) if f.endswith('.png')]\n",
    "    depth_files = {f for f in os.listdir(image_directory) if f.endswith('.tif')}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for mask_file in mask_files:\n",
    "        base_name = os.path.splitext(mask_file)[0]\n",
    "        depth_file = f\"{base_name}.tif\"\n",
    "\n",
    "        if depth_file in depth_files:\n",
    "            mask_path = os.path.join(mask_directory, mask_file)\n",
    "            depth_map_path = os.path.join(image_directory, depth_file)\n",
    "\n",
    "            mask = skimage.io.imread(mask_path)\n",
    "            depth_map = tifffile.imread(depth_map_path)\n",
    "\n",
    "            # Extract 'cow' and 'day' from filename\n",
    "            cow, day = extract_cow_day(mask_file)\n",
    "\n",
    "            # Compute distances & shape features\n",
    "            center_points = calculate_vertical_center_points(mask)\n",
    "            if len(center_points) > 2:\n",
    "                center_points = center_points[1:-1]\n",
    "\n",
    "            center_y_points = [(cy, c) for cy, c, _, _, _ in center_points]\n",
    "            widths = [w for _, _, _, _, w in center_points]\n",
    "\n",
    "            distances = calculate_distances(depth_map, center_y_points)\n",
    "            shape_features = calculate_shape_features(mask, depth_map)\n",
    "\n",
    "            # Save results\n",
    "            results.append([mask_file, cow, day] + distances + widths + shape_features)\n",
    "\n",
    "            # Save visualization\n",
    "            plt.imshow(mask, cmap='gray')\n",
    "            for cy, c in center_y_points:\n",
    "                plt.plot(c, cy, 'yo')\n",
    "            for cy, c, top, bottom, _ in center_points:\n",
    "                plt.plot([c, c], [top, bottom], 'r-')\n",
    "\n",
    "            plt.savefig(os.path.join(output_directory, f\"{base_name}_graph.png\"))\n",
    "            plt.close()\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(results, columns=['Image Name', 'cow', 'day'] +\n",
    "                      [f'Distance_{i+1}' for i in range(11)] +\n",
    "                      [f'Width_{i+1}' for i in range(11)] +\n",
    "                      ['Area', 'Volume', 'Circularity', 'Extent', 'Eccentricity', 'Perimeter', 'Major_Axis_Length'])\n",
    "\n",
    "    df.to_csv(os.path.join(output_directory, 'distances_shape_features_results.csv'), index=False)\n",
    "\n",
    "def compute_averages(df):\n",
    "    \"\"\"Group data by cow and day, computing averages for numeric columns.\"\"\"\n",
    "    numeric_columns = df.columns[3:]\n",
    "\n",
    "    # Convert relevant columns to numeric\n",
    "    df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Ensure 'cow' and 'day' are strings before grouping\n",
    "    df[['cow', 'day']] = df[['cow', 'day']].astype(str)\n",
    "\n",
    "    return df.groupby(['cow', 'day'], as_index=False)[numeric_columns].mean()\n",
    "\n",
    "def merge_bw_data(df_new, bw_file_path):\n",
    "    \"\"\"Merge body weight (BW) data based on cow and day.\"\"\"\n",
    "    df_bw = pd.read_csv(bw_file_path, dtype={'day': str, 'cow': str})\n",
    "    df_new[['day', 'cow']] = df_new[['day', 'cow']].astype(str)\n",
    "    return df_new.merge(df_bw, on=['cow', 'day'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rO5UftA4yUfy"
   },
   "source": [
    "\n",
    "# MAIN EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1740520096683,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "RAxpMJnryBau"
   },
   "outputs": [],
   "source": [
    "# Define directories\n",
    "main_dir = 'depth'\n",
    "image_directory = os.path.join(main_dir,'Images')\n",
    "\n",
    "save_dir = os.path.join(main_dir, 'output')\n",
    "mask_directory = os.path.join(save_dir, 'masks')\n",
    "output_directory = os.path.join(save_dir,'graphs')\n",
    "\n",
    "# create the ouput directories\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(mask_directory, exist_ok=True)\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 135294,
     "status": "ok",
     "timestamp": 1740520231977,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "ANwW4uxFyL0o"
   },
   "outputs": [],
   "source": [
    "# Process images\n",
    "process_images(image_directory, mask_directory, output_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163,
     "status": "ok",
     "timestamp": 1740520232138,
     "user": {
      "displayName": "Maria Elisa Montes Gonzalez",
      "userId": "04792630582788233084"
     },
     "user_tz": 360
    },
    "id": "TQOkzYGMyTln",
    "outputId": "6b0e2748-869e-4afe-8fa8-dae811add80e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Results saved to /content/drive/MyDrive/guilherme/depth/output/results_bw.csv.\n"
     ]
    }
   ],
   "source": [
    "# Load and process data\n",
    "output_csv_path = os.path.join(output_directory, 'distances_shape_features_results.csv')\n",
    "df = pd.read_csv(output_csv_path)\n",
    "\n",
    "# Compute averages\n",
    "df_new = compute_averages(df)\n",
    "\n",
    "# Merge BW data\n",
    "bw_file_path = os.path.join(main_dir,'DF','BW.csv')\n",
    "df_new = merge_bw_data(df_new, bw_file_path)\n",
    "\n",
    "# Save final data\n",
    "output_csv = os.path.join(save_dir, \"results_bw.csv\")\n",
    "df_new.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Processing complete. Results saved to {output_csv}.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN13lwrYRKHIPTSRxlAM7Yv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
